{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa76e2b-66b2-4d9f-9566-c9acb2c068db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d20bba-0431-4613-b450-3f117fad8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = \"/shared/3/projects/benlitterer/podcastData/hostIdentification/trainTestVal2_5/descTrainLabelled.csv\"\n",
    "df = pd.read_csv(inPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb6e73d-85b1-40e6-a383-cee7e8446a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30158, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fdb6f9-a2da-4404-bc34-ca9ee91c5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884864e8-8911-475f-9f8b-124b8f94f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"left\", \"ent\", \"right\"]] = df[[\"left\", \"ent\", \"right\"]].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa14b573-5086-4117-bc89-cf7a0d8e9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fullSnip\"] = df[\"left\"] + df[\"ent\"] + df[\"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7a91fc-63a5-442e-a87e-046299fd0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceNum = 1\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df2c238-8769-4316-b4bd-3e2b73c34c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-08 18:07:55,785] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192ba927-4120-4579-8eba-427d29c4369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/298 [00:00<?, ?it/s]/opt/anaconda/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      " 90%|████████▉ | 267/298 [00:29<00:03,  8.33it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 298/298 [00:33<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "outPred = []\n",
    "for snip in tqdm(df[\"fullSnip\"]):  \n",
    "    prefix = \"Output the full name of the podcast hosts in the following sequence of text, and if there is no host output NONE instead: \"  \n",
    "    inputs = tokenizer(f\"{prefix} {snip}\", return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    outPred.append(decoded) \n",
    "    #print(snip) \n",
    "    #print(decoded) \n",
    "    #print(\"----------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4774aa21-e570-4148-9c13-ee8fefc7e710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NONE'],\n",
       " ['NONE instead:'],\n",
       " ['Geneviève Kyle-Lefebvre'],\n",
       " ['Robert Waterbury'],\n",
       " ['Nicole Scherzinger'],\n",
       " ['Richard Grannon'],\n",
       " ['Greg Garcia'],\n",
       " ['Christian faith based Ecumenical poems'],\n",
       " ['Mark Hawkinson'],\n",
       " ['Tiny Leaps, Big Changes']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outPred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc41fa1-a966-4f7f-8d21-e27b591bcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outCol = pd.DataFrame(outPred, columns=[\"FLANT5oneShot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba00173-9313-4d50-af71-eb2318e761a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outCol.to_csv(\"/shared/3/projects/benlitterer/podcastData/hostIdentification/FLANTT5/earlyExperiments/descTrainTest.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
