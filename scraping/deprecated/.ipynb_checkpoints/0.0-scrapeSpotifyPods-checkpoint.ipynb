{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import pandas as pd\n",
    "import base64\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import atexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientId = \"29eecbec66ab437a87aa008be0c6755e\"\n",
    "clientSecret = \"4e7e3bd31b634a85981d3191e686409c\"\n",
    "clientCreds = f\"{clientId}:{clientSecret}\"\n",
    "clientCredsB64 = base64.b64encode(clientCreds.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "tokenHeads = {\"Authorization\":f\"Basic {clientCredsB64.decode()}\"}\n",
    "\n",
    "tokenParams = {\"grant_type\":\"client_credentials\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToken(): \n",
    "    tokResponse = req.post(url, data=tokenParams, headers=tokenHeads)\n",
    "    tokData = tokResponse.json()\n",
    "    token = tokData[\"access_token\"]\n",
    "    return token \n",
    "\n",
    "currTok = getToken()\n",
    "\n",
    "#now that we have our access token we can use the spotify api!\n",
    "baseUrl = \"https://api.spotify.com/\"\n",
    "headers = {\"Authorization\": f\"Bearer {currTok}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searchQ = \"Joe Rogan\"\n",
    "\n",
    "#give search information, get the json object returned \n",
    "def searchPod(searchQ, limit=50, inHeaders, market=\"US\", type_=\"show\"): \n",
    "    #format our url appropriately \n",
    "    fUrl = f'{baseUrl}v1/search?q={searchQ.replace(\" \", \"+\")}&type={type_}&market={market}&limit={limit}'\n",
    "    searchRes = req.get(fUrl, headers=inHeaders)\n",
    "    \n",
    "    #return response code, dictionary of podcast information \n",
    "    return [searchRes.status_code, searchRes.json()]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HITS = 100\n",
    "\n",
    "#set up an output file, if this file already exists, decide where to start searching from \n",
    "#we want to either write a new file, or append \n",
    "#to a file we've already written \n",
    "OUT_FILE =  \"/shared/3/projects/benlitterer/podcastData/podNames/TESTpodinfo.csv\"\n",
    "SEARCH_LIST = \"/shared/3/projects/benlitterer/podcastData/podNames/TESThits.csv\"\n",
    "\n",
    "#get the podcasts we've already searched an initialize searched \n",
    "if os.path.exists(OUT_FILE): \n",
    "    outHandle = open(OUT_FILE, \"a+\")\n",
    "    \n",
    "    #IF the file exists, we want to decide where to start searching and appending \n",
    "    #prevDf = pd.read_csv(OUT_FILE, names=OUT_COLS)\n",
    "    colNames = [\"searchName\", \"hitName\", \"type\", \"languages\", \"description\", \"is_externally_hosted\", \"total_episodes\"]\n",
    "    prevDf = pd.read_csv(OUT_FILE, names=colNames)\n",
    "    \n",
    "    #get all of the podcasts which have already been searched \n",
    "    #so we don't search them again \n",
    "    searched = set(prevDf[\"searchName\"])\n",
    "        \n",
    "    \n",
    "else: \n",
    "    outHandle = open(OUT_FILE, \"w+\")\n",
    "    searched = set([]) \n",
    "    \n",
    "#if we have a previous search set, use that\n",
    "#if not, default to our seeds \n",
    "if os.path.exists(SEARCH_LIST): \n",
    "    #get the list of hits to keep searching \n",
    "    hits = pd.read_csv(SEARCH_LIST, names=[\"hitName\"], index_col=False)\n",
    "    hits = list(hits[\"hitName\"])\n",
    "    \n",
    "    #but we only want the last X number of hits \n",
    "else: \n",
    "    hitsHandle = open(SEARCH_LIST, \"w+\")\n",
    "    #if we don't have previous hits to use, \n",
    "    #seed with the top 20 podcasts on spotify \n",
    "    hits = [\"Joe Rogan\", \n",
    "            \"The Really Good Podcast\", \n",
    "            \"Huberman Lab\", \n",
    "            \"anything goes with emma chamberlain\", \n",
    "            \"This Past Weekend\", \n",
    "            \"Crime Junkie\", \n",
    "            \"Smartless\", \n",
    "            \"Shawn Ryan Show\", \n",
    "            \"Scamanda\", \n",
    "            \"Call Her Daddy\", \n",
    "            \"PBD Podcast\", \n",
    "            \"Rotten Mango\", \n",
    "            \"Date Yourself Instead\", \n",
    "            \"Distractible\", \n",
    "            \"The Retrievals\", \n",
    "            \"The Daily\", \n",
    "            \"2 Bears, 1 Cave with Tom Segura & Bert Kreischer\", \n",
    "            \"Morbid\", \n",
    "            \"The Broski Report with Brittany Broski\", \n",
    "            \"The LOL Podcast\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exit_handler()>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exit_handler():\n",
    "    if os.path.exists(OUT_FILE): \n",
    "        outHandle.close()\n",
    "        \n",
    "    if os.path.exists(SEARCH_LIST):\n",
    "        hitsHandle.close()\n",
    "\n",
    "atexit.register(exit_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-38ada06d759b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlimitCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaitTime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;31m#search the previous hit using spotify api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mresCode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhitRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchPod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: switch this over so that it writes to files rather than staying in memory \n",
    "\n",
    "#keep searching over and over exponentially \n",
    "#for each episode in hits, search that episode and add the results to the news version of hits \n",
    "#keep doing this, while ensuring that we don't search something we've already searched \n",
    "\n",
    "#the new hits at each level of search tree\n",
    "#and all of our hits we've ever gotten \n",
    "newHits = []\n",
    "\n",
    "#for printing reasons\n",
    "counter = 0 \n",
    "\n",
    "#for rate limit reasons...\n",
    "waitTime = 2\n",
    "MIN_WAIT = 2\n",
    "goodCode = True\n",
    "\n",
    "while True: \n",
    "    #for each hit, we search \n",
    "    for hit in hits: \n",
    "\n",
    "        #don't search something we've already searched \n",
    "        #TODO: this gets slow as allHits grows \n",
    "        if hit not in searched: \n",
    "\n",
    "            #we break at the end of this while loop \n",
    "            #so long as we get a good response code from the spotify api \n",
    "            limitCount = 0 \n",
    "            while True: \n",
    "                time.sleep(waitTime + random.random())\n",
    "                #search the previous hit using spotify api \n",
    "                resCode, hitRes = searchPod(hit)\n",
    "                \n",
    "                #only exit if we aren't being rate limited\n",
    "                if resCode != 429: \n",
    "                    #just issue a warning if we hit a non 200 response code \n",
    "                    if resCode != 200: \n",
    "                        print(f\"warning! exit code {resCode}\")\n",
    "                              \n",
    "                    if resCode == 401: \n",
    "                        currTok = getToken()\n",
    "                        \n",
    "                    #lower our wait time if it's not at minimum \n",
    "                    if waitTime > MIN_WAIT: \n",
    "                        waitTime = np.sqrt(waitTime)\n",
    "                        print(f\"wait time = {waitTime}\")\n",
    "                    break \n",
    "                else:\n",
    "                    \n",
    "                    #increase wait time exponentially if being rate limited \n",
    "                    waitTime = waitTime**2\n",
    "                    print(f\"wait time = {waitTime}\")\n",
    "            \n",
    "            searched.update(hit)\n",
    "            outStr = \"\"\n",
    "            #write hit information to file \n",
    "            if \"shows\" in hitRes: \n",
    "\n",
    "                #for each show returned from this search \n",
    "                for show in hitRes[\"shows\"][\"items\"]: \n",
    "                    keepList = [\"name\", \"type\", \"languages\", \"description\", \"is_externally_hosted\", \"total_episodes\"]\n",
    "\n",
    "                    #if we have the field we want, add to outRow else blank space \n",
    "                    #we want to avoid double quotes in our file output as well \n",
    "                    outRow = []\n",
    "                    for k in keepList: \n",
    "                        if k in show:\n",
    "                            val = show[k]\n",
    "                            if type(val) == list: \n",
    "                                val = \",\".join(val)\n",
    "                            elif type(val) != str: \n",
    "                                val = str(val)\n",
    "                                \n",
    "                            val = val.replace('\"', '')\n",
    "                            outRow.append(val)\n",
    "                        else: \n",
    "                            outRow.append(\"\")\n",
    "                    \n",
    "                    #add the search podcast to our output \n",
    "                    outRow = [hit] + outRow\n",
    "\n",
    "                    #the name of the search result podcast \n",
    "                    name = outRow[1].replace('\"', '')\n",
    "                    \n",
    "                    #make outRow a string ready to be written to file \n",
    "                    outRow = '\",\"'.join(outRow)\n",
    "                    outRow = f'\"{outRow}\"\\n'\n",
    "\n",
    "                    #add the string with this row\n",
    "                    #to the larger string we will write to output\n",
    "                    outStr += outRow\n",
    "\n",
    "                    #update lists of what we've searched and what we will search next \n",
    "                    #but only if we haven't already searched this podcast \n",
    "                    if name not in searched: \n",
    "                        newHits.append(name)\n",
    "                        #allHits.update({name})\n",
    "\n",
    "                #write string for podcast information to file \n",
    "                outHandle.write(outStr)\n",
    "                \n",
    "                #force the buffer to write to file\n",
    "                outHandle.flush()\n",
    "        \n",
    "    #the hits we just got will be our new list to search\n",
    "    #we will add the results from these new searches to newHits \n",
    "    #we also don't want our list of pods to search to get to large, \n",
    "    #so we prune out our list randomly as we go\n",
    "    if len(newHits) > MAX_HITS: \n",
    "        hits = random.sample(newHits, MAX_HITS)\n",
    "    else: \n",
    "        hits = newHits \n",
    "            \n",
    "    #write our current hits list to output file \n",
    "    hitsHandle = open(SEARCH_LIST, \"w+\")\n",
    "    hitsStr = '\",\\n\"'.join(hits)\n",
    "    hitsStr = f'\"{hitsStr}\"'\n",
    "    hitsHandle.write(hitsStr)\n",
    "    hitsHandle.close()\n",
    "    #for the next round of hits to go in \n",
    "    newHits = []\n",
    "    print(\"finished level\")\n",
    "    print(f\"now searching through {len(hits)} new hits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_handler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
